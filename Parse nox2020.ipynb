{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858ff0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "336e1e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_path = 'NOXSOXPM-ISA-FINAL-SEP-2020.html'\n",
    "csv_path = 'nox_2020_citation_table_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf906d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(html_path, 'r', encoding='cp1252')\n",
    "contents = f.read()\n",
    "soup = BeautifulSoup(contents,'html.parser')\n",
    "soup.prettify(formatter=lambda s: s.replace(u'\\xa0', ' ').replace(\"&nbsp;\", ' '))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea08adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_heading(s):\n",
    "    if s.startswith('IS.') or s.startswith('ES.'):\n",
    "        return True\n",
    "    if re.search(r'^\\d+\\..+\\s{5,7}', s) is not None:\n",
    "        return True\n",
    "    if s.startswith('PREFACE') or (s.startswith('EXECUTIVE') and 'SUMMARY' in s) or (s.startswith('INTEGRATED') and 'SYNTHESIS' in s) or s.startswith('APPENDIX'):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42d376ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(t):\n",
    "    t = t.replace('‘', \"'\").replace('’', \"'\").replace('“', '\"').replace('”', '\"').replace('‑', '-').replace('·', '').replace('־', '-').replace('−', '-').replace('×', 'x')\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1671b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(csv_path, 'w', encoding='utf-8',newline='')\n",
    "csv_r = csv.writer(f)\n",
    "i = 0\n",
    "level1 = '-'\n",
    "level2 = '-'\n",
    "level3 = '-'\n",
    "level4 = '-'\n",
    "level5 = '-'\n",
    "level6 = '-'\n",
    "\n",
    "row = ['INSTANCE_ID', 'REFERENCE_ID', 'Level1', 'Level2', 'Level3', 'Level4', 'Level5', 'Level6', 'AnchorText', 'ContextParagraph']\n",
    "csv_r.writerow(row)\n",
    "\n",
    "for tag in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'h8']):\n",
    "    # print(f'{tag.name}: {tag.text}')\n",
    "    \n",
    "    tag_text = process_text(tag.text)\n",
    "\n",
    "    if is_heading(tag.text) and len(tag.text.split()[0].split('.')) == 1:\n",
    "        level1 = tag_text\n",
    "        # print ('PART', part)\n",
    "    \n",
    "    if is_heading(tag.text) and len(tag.text.split()[0].split('.')) == 2:\n",
    "        level2 = tag_text\n",
    "        # print ('CHAPTER', chapter)\n",
    "    \n",
    "    if is_heading(tag.text) and len(tag.text.split()[0].split('.')) == 3:\n",
    "        level3 = tag_text\n",
    "        # print ('SECTION', section)\n",
    "        \n",
    "    if is_heading(tag.text) and len(tag.text.split()[0].split('.')) == 4:\n",
    "        level4 = tag_text\n",
    "        # print ('SUBSECTION', subsection)\n",
    "        \n",
    "    if is_heading(tag.text) and len(tag.text.split()[0].split('.')) == 5:\n",
    "        level5 = tag_text\n",
    "        \n",
    "    if is_heading(tag.text) and len(tag.text.split()[0].split('.')) == 6:\n",
    "        level6 = tag_text\n",
    "        \n",
    "    pre_hero_id=\"\"\n",
    "    pre_tag_text=\"\"\n",
    "    anchor_text = \"\"\n",
    "\n",
    "    for subtag in tag.descendants: # write out all citations in the current paragraph\n",
    "        if subtag.name == 'a' and 'href' in subtag.attrs:\n",
    "            if 'hero' in subtag.attrs['href'] and 'reference_id' in subtag.attrs['href']:\n",
    "                i += 1\n",
    "                hero_id = subtag.attrs['href'].split('=')[-1]\n",
    "                \n",
    "\n",
    "                if re.search(r'\\d+', hero_id) is not None:\n",
    "                    if pre_hero_id == hero_id and tag_text == pre_tag_text:\n",
    "                        anchor_text += subtag_text\n",
    "\n",
    "                    else:\n",
    "                        anchor_text = subtag_text\n",
    "                    \n",
    "                    \n",
    "                    if level1 == 'PREFACE': # chapter, section, and subsections were from the TOC before FREFACE\n",
    "                        s_level2, s_level3, s_level4, s_level5, s_level6 = '-', '-', '-', '-', '-'\n",
    "                    else:\n",
    "                        s_level2 = level2\n",
    "\n",
    "                    if level3.startswith(level2.split()[0]):\n",
    "                        s_level3 = level3\n",
    "                        if level4.startswith(level3.split()[0]):\n",
    "                            s_level4 = level4\n",
    "                            if level5.startswith(level4.split()[0]):\n",
    "                                s_level5 = level5\n",
    "                                if level6.startswith(level5.split()[0]):\n",
    "                                    s_level6 = level6\n",
    "                                else:\n",
    "                                    s_level6 = '-'\n",
    "                            else:\n",
    "                                s_level5 = '-'\n",
    "                                s_level6 = '-'\n",
    "                        else:\n",
    "                            s_level4 = '-'\n",
    "                            s_level5 = '-'\n",
    "                            s_level6 = '-'\n",
    "                    else:\n",
    "                        s_level3 = '-'\n",
    "                        s_level4 = '-'\n",
    "                        s_level5 = '-'\n",
    "                        s_level6 = '-'\n",
    "                    \n",
    "                    subtag_text = process_text(subtag.text)\n",
    "                    row = [str(i), hero_id, level1, s_level2, s_level3, s_level4, s_level5, s_level6, anchor_text, tag_text]\n",
    "                    csv_r.writerow(row)\n",
    "                    pre_hero_id = hero_id\n",
    "                    pre_tag_text = tag_text\n",
    "                \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16778340",
   "metadata": {},
   "source": [
    "## Reformat: remove instances, separate header sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "327f0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(input_path, output_path):\n",
    "    \n",
    "    in_f = open(input_path, 'r', encoding='utf-8',newline='')\n",
    "    out_f = open(output_path, 'w', encoding='utf-8',newline='')\n",
    "\n",
    "    csv_r = csv.reader(in_f)\n",
    "    next(csv_r, None) # skip header\n",
    "    \n",
    "    csv_w = csv.writer(out_f)\n",
    "    header = ['INSTANCE_ID', 'REFERENCE_ID']\n",
    "    header += ['level_all_num', 'level1_num', 'level2_num', 'level3_num', 'level4_num', 'level5_num', 'level6_num']\n",
    "    header += ['level1_char', 'level2_char', 'level3_char', 'level4_char', 'level5_char', 'level6_char']\n",
    "    header += ['ANCHOR_TEXT', 'CONTEXT_PARAGRAPH']\n",
    "    csv_w.writerow(header)\n",
    "    \n",
    "    i = 1\n",
    "    csv_r = list(csv_r)\n",
    "    length = len(csv_r)\n",
    "    for index,row in enumerate(csv_r):\n",
    "        INSTANCE_ID, REFERENCE_ID, Level1, Level2, Level3, Level4, Level5, Level6, AnchorText, ContextParagraph = row\n",
    "        if index<length-1:\n",
    "            _, next_re_id, _, _, _, _, _, _, next_anchor, next_context = csv_r[index+1]\n",
    "        \n",
    "        if (REFERENCE_ID == next_re_id) and (next_anchor.startswith(AnchorText))and(ContextParagraph[:20] == next_context[:20]):\n",
    "            continue     \n",
    "        \n",
    "        level1_num = '.'\n",
    "        level1_txt = ''\n",
    "        level2_num = '.'\n",
    "        level2_txt = ''\n",
    "        level3_num = '.'\n",
    "        level3_txt = ''\n",
    "        level4_num = '.'\n",
    "        level4_txt = ''\n",
    "        level5_num = '.'\n",
    "        level5_txt = ''\n",
    "        level6_num = '.'\n",
    "        level6_txt = ''\n",
    "        \n",
    "        if Level1 != '-':\n",
    "            if Level1 == 'PREFACE' or Level1 == 'EXECUTIVE SUMMARY' or Level1 == 'INTEGRATED SYNTHESIS':\n",
    "                level1_num = '0'\n",
    "                level1_txt = Level1\n",
    "            else:\n",
    "                level1_num = Level1.split(' ', 2)[1]\n",
    "                level1_txt = ' '.join(Level1.split(' ', 2)[:2] + ['|'] + Level1.split(' ', 2)[2:])\n",
    "            section_num = level1_num\n",
    "            section_txt = level1_txt\n",
    "        if Level2 != '-':\n",
    "            level2_num = Level2.split(' ', 1)[0].split('.')[1]\n",
    "            level2_txt = Level2.split(' ', 1)[1]\n",
    "            section_num, section_txt = Level2.split(' ', 1)\n",
    "        if Level3 != '-':\n",
    "            level3_num = Level3.split(' ', 1)[0].split('.')[2]\n",
    "            level3_txt = Level3.split(' ', 1)[1]\n",
    "            section_num, section_txt = Level3.split(' ', 1)\n",
    "        if Level4 != '-':\n",
    "            level4_num = Level4.split(' ', 1)[0].split('.')[3]\n",
    "            level4_txt = Level4.split(' ', 1)[1]\n",
    "            section_num, section_txt = Level4.split(' ', 1)\n",
    "        if Level5 != '-':\n",
    "            level5_num = Level5.split(' ', 1)[0].split('.')[4]\n",
    "            level5_txt = Level5.split(' ', 1)[1]\n",
    "            section_num, section_txt = Level5.split(' ', 1)\n",
    "        if Level6 != '-':\n",
    "            level6_num = Level6.split(' ', 1)[0].split('.')[5]\n",
    "            level6_txt = Level6.split(' ', 1)[1]\n",
    "            section_num, section_txt = Level6.split(' ', 1)\n",
    "            \n",
    "        new_row = [str(i), REFERENCE_ID]\n",
    "        new_row += [section_num, level1_num, level2_num, level3_num, level4_num, level5_num, level6_num]\n",
    "        new_row += [level1_txt, level2_txt, level3_txt, level4_txt, level5_txt, level6_txt]\n",
    "        new_row += [AnchorText, ContextParagraph]\n",
    "        csv_w.writerow(new_row)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    in_f.close()\n",
    "    out_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d0a23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csv_path = 'nox_2020_citation_table.csv'\n",
    "reformat(csv_path, new_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f2b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
